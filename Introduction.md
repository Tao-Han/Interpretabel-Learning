# Interpretabel Machine Learning

This page provides some learning materials and notes for **Interpretable Machine Learning** and I would like to share my personal opinions on some papers.

## **What** is Interpretability and **Why** we need it

### The following papers made an attepmt to clarify the definition, intension, intuition and motivation of Interpretable Machine Learning.

- [Feb 2016 : "Why Should I Trust You?": Explaining the Predictions of Any Classifier](https://arxiv.org/abs/1602.04938) 
  - Intuition
    - Explanation components (semantic components as features)
    - Local fidelity (locally loyal to the model being interpreted)
    - Limited complexity (rule/feature numbers, tree depth)
    - Model interpretability can be achieved by the Instance interpretability of representative instances
  - Model
    - LIME: Sparse Linear Model similar to Lasso

- [Jun 2016 : The Mythos of Model Interpretability](https://arxiv.org/abs/1606.03490) 

- [Feb 2017 : Towards A Rigorous Science of Interpretable Machine Learning](https://arxiv.org/abs/1702.08608) 

### Generally, these papers tried to build up the basis of Interpretable Machine Learning and I would like to summerize here for advice.

- Interpretability is
  - to present abstract concept in an understandable term for humans
  - ...

- Interpretability for
  - the prediction of a specific instance
  - the mechanism of the whole model
- Benefit
  - applications in critical fileds
  - the performance of model (remove some useless part in complex model)
  - the study of complex model
  - ...
- Evaluation
  - Proxy metrics
  - People invovled




# Detailed Notes in 2018-11

1. [Feb 2018: Explanations based on the Missing: Towards Contrastive Explanations with Pertinent Negatives(NIPS2018)](http://cn.arxiv.org/abs/1802.07623)

- **Motivation**
  - Many existed works pay little attention to the absent features, which are as important as the present ones.
  - Explain the prediction of model by answering what factor is present and what is absent.
  - To realize this idea, show the contrastive facts (features and class).
- **Model**
  - Definition
    - Pertinent Positive (**PP**): present factor minimally sufficient to get the final classification.
    - Pertinent Negative (**PN**): absent factor necessary to assert the final classification.
  - Contrastive Explanation Method (**CEM**)
    - Find PN
      1. Perturb instance by adding the absent features
      2. Minimize the loss of not changing prediction, instance reconstruction and structure risk.
    - Find PP
      1. Perturb instance by removing the present features
      2. Minimize the loss of not changing prediction, instance reconstruction and structure risk.
- **Evaluation**
  - The experiments include MNIST, fraud prediction and fMRI.
  - The evaluation is through visualization comparison and expert feedback.
- **Notes**
  - The motivation is convincible: decision comes from comparison.
  - I think take absence as a new feature adding into dataset then traditional models may achieve similar result.
  - The loss may associate with **Large Margin Loss**. Larger the class margin, better may the model be.

2. [May 2018: To Trust Or Not To Trust A Classifier (NIPS2018)](https://arxiv.org/abs/1805.11783)

- **Motivation**
  - The former methods to measure a prediction's trustworthiness depend on the model's discriminant or confidence score, which is not objective and reliable.
  - Some works have been proposed to modify the confidence or learn the model with a reject function.
  - This work will treat the original model as a black-box to measure its prediction
- **Model**
  1. For each class filter the data into a more dense set called $\alpha$-high density set. Estimate the set with k-neighbors density larger than parameter alpha.
  2. For a specific test sample x and the model's prediction l, compute the ratio between two distances:
     - trust_score(x, l) = D(x, NearestLabelSet_except_class_l) / D(x, LabelSet_class_l)
     - Obviously, higher the score, larger the distance margin, which means more trustworthy.
  3. Analysis of alg1 and alg2 plays an importance role.
     - Alg 1 is a consistent estimation of $\alpha$-high density set.
     - Alg 2 is agree with the Bayes-optimal classifier under some mild assumptions.
- **Evaluation**
  - The experiments show that for low-dimensional data, the trust score performs better than confidence score and 1-NN ration.
  - However for high-dimension data, its performance is no better.
- **Notes**
  - The k-NN has a well-known connection with Bayes-Optimal Classifier (BOC), the paper utilizes the knowledge.
  - The trust score can be viewed as a modified k-NN to approximate BOC.
  - The environment of trustworthiness does not match what the experiments shows. It should be somehow unstable and complex such as online learning, weak supervised learning etc.
# Interpretabel Machine Learning

This Page provides some learning materials and notes for **Interpretable Machine Learning** and I would like to share some of my personal opinions on some papers.

## **What** is Interpretability and **Why** we need it

---

### The following papers made attepmt to clarify the definition, intension , intuition and motivation of Interpretable Machine Learning.

- [Feb 2016 : "Why Should I Trust You?": Explaining the Predictions of Any Classifier](https://arxiv.org/abs/1602.04938) 
  - Intuition
    - Explanation components (semantic components as features)
    - Local fidelity (locally loyal to the model being interpreted)
    - Limited complexity (rule/feature numbers, tree depth)
  - Model
    - LIME: Sparse Linear Model similar to Lasso

- [Jun 2016 : The Mythos of Model Interpretability](https://arxiv.org/abs/1606.03490) 

- [Feb 2017 : Towards A Rigorous Science of Interpretable Machine Learning](https://arxiv.org/abs/1702.08608) 

### Generally, these papers tried to build up the basis of Interpretable Machine Learning and I would like to summerize here for advice.

- Interpretability is
  - present abstract concept in an understandable term for humans
  - ...

- Interpretability for
  - the prediction of a specific instance
  - the mechanism of the whole model
- Benefit
  - applications in critical fileds
  - the performance of model
  - the study of complex model
  - ...
- 
- Evaluation
  - Proxy metrics
  - People invovled

## **How** can we obtain interpretability?

---

The following papers gave us some angles to obtain interpretablity

#